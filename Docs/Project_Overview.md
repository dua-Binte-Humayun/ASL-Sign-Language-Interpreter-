## Project Overview

The ASL Sign Language Interpreter is an AI-driven assistive system designed to translate static American Sign Language (ASL) hand gestures into text using computer vision and machine learning.

The project focuses on real-time interaction, usability, and accessibility. Unlike purely technical models, this work emphasizes how users experience and interact with intelligent systems, making it particularly relevant to HCI research.

The system consists of:
- Webcam-based gesture capture
- Image preprocessing
- Feature extraction
- Machine learning-based classification
- Text-based output interface

This project was developed as part of advanced undergraduate research work and reflects a strong interest in accessible AI and healthcare-related applications.
